{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8715b416",
      "metadata": {
        "id": "8715b416"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42f55af",
      "metadata": {
        "id": "e42f55af"
      },
      "outputs": [],
      "source": [
        "inWidth = 368\n",
        "inHeight = 368\n",
        "thr = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fae40a5",
      "metadata": {
        "id": "0fae40a5"
      },
      "outputs": [],
      "source": [
        "net = cv.dnn.readNetFromTensorflow('/content/drive/MyDrive/capstone/graphopt/graph_opt.pb') #weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NRmDLpDJnNG",
        "outputId": "dffbc8d6-7ddf-44fc-a400-1262940fdea5"
      },
      "id": "_NRmDLpDJnNG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150fed8a",
      "metadata": {
        "id": "150fed8a"
      },
      "outputs": [],
      "source": [
        "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
        "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
        "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
        "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
        "\n",
        "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
        "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
        "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
        "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
        "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b69830e",
      "metadata": {
        "id": "5b69830e"
      },
      "outputs": [],
      "source": [
        "def pose_estimation(frame):\n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
        "    out = net.forward()\n",
        "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
        "\n",
        "    assert(len(BODY_PARTS) == out.shape[1])\n",
        "\n",
        "    points = []\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "        # Slice heatmap of corresponging body's part.\n",
        "        heatMap = out[0, i, :, :]\n",
        "\n",
        "        # Originally, we try to find all the local maximums. To simplify a sample\n",
        "        # we just find a global one. However only a single pose at the same time\n",
        "        # could be detected this way.\n",
        "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
        "        x = (frameWidth * point[0]) / out.shape[3]\n",
        "        y = (frameHeight * point[1]) / out.shape[2]\n",
        "        # Add a point if it's confidence is higher than threshold.\n",
        "        points.append((int(x), int(y)) if conf > args.thr else None)\n",
        "\n",
        "    for pair in POSE_PAIRS:\n",
        "        partFrom = pair[0]\n",
        "        partTo = pair[1]\n",
        "        assert(partFrom in BODY_PARTS)\n",
        "        assert(partTo in BODY_PARTS)\n",
        "\n",
        "        idFrom = BODY_PARTS[partFrom]\n",
        "        idTo = BODY_PARTS[partTo]\n",
        "\n",
        "        if points[idFrom] and points[idTo]:\n",
        "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
        "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "    freq = cv.getTickFrequency() / 1000\n",
        "    cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "\n",
        "    cv.imshow('OpenPose using OpenCV', frame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "Pfp_8WuoKJbe"
      },
      "id": "Pfp_8WuoKJbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ea9129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e2ea9129",
        "outputId": "18a20aa4-8b3f-48ed-f992-95fe78c560ee"
      },
      "outputs": [],
      "source": [
        "cap = cv.VideoCapture('/content/drive/MyDrive/capstone/single pose/Ahtesham Hussain crossing the road.mp4')\n",
        "\n",
        "for i in range(0,30):\n",
        "    hasFrame, frame = cap.read()\n",
        "    if not hasFrame:\n",
        "        cv.waitKey()\n",
        "        break\n",
        "        \n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
        "    out = net.forward()\n",
        "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
        "\n",
        "    assert(len(BODY_PARTS) == out.shape[1])\n",
        "\n",
        "    points = []\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "        # Slice heatmap of corresponging body's part.\n",
        "        heatMap = out[0, i, :, :]\n",
        "\n",
        "        # Originally, we try to find all the local maximums. To simplify a sample\n",
        "        # we just find a global one. However only a single pose at the same time\n",
        "        # could be detected this way.\n",
        "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
        "        x = (frameWidth * point[0]) / out.shape[3]\n",
        "        y = (frameHeight * point[1]) / out.shape[2]\n",
        "        # Add a point if it's confidence is higher than threshold.\n",
        "        points.append((int(x), int(y)))\n",
        "    \n",
        "    print(points)\n",
        "    print(len(points))\n",
        "\n",
        "    for pair in POSE_PAIRS:\n",
        "        partFrom = pair[0]\n",
        "        partTo = pair[1]\n",
        "        assert(partFrom in BODY_PARTS)\n",
        "        assert(partTo in BODY_PARTS)\n",
        "\n",
        "        idFrom = BODY_PARTS[partFrom]\n",
        "        idTo = BODY_PARTS[partTo]\n",
        "\n",
        "        if points[idFrom] and points[idTo]:\n",
        "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
        "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "    freq = cv.getTickFrequency() / 1000\n",
        "    cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "    print(points)\n",
        "    \n",
        "    cv2_imshow(frame)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e81e6f",
      "metadata": {
        "id": "f1e81e6f"
      },
      "outputs": [],
      "source": [
        "def getpoints(path):\n",
        "  cap = cv.VideoCapture(path)\n",
        "  for i in range(0,30):\n",
        "    hasFrame, frame = cap.read()\n",
        "    if not hasFrame:\n",
        "      cv.waitKey()\n",
        "      break\n",
        "        \n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
        "    out = net.forward()\n",
        "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
        "\n",
        "    assert(len(BODY_PARTS) == out.shape[1])\n",
        "\n",
        "    points = []\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "        # Slice heatmap of corresponging body's part.\n",
        "        heatMap = out[0, i, :, :]\n",
        "\n",
        "        # Originally, we try to find all the local maximums. To simplify a sample\n",
        "        # we just find a global one. However only a single pose at the same time\n",
        "        # could be detected this way.\n",
        "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
        "        x = (frameWidth * point[0]) / out.shape[3]\n",
        "        y = (frameHeight * point[1]) / out.shape[2]\n",
        "        # Add a point if it's confidence is higher than threshold.\n",
        "        points.append((int(x), int(y)))\n",
        "    \n",
        "    print(points)\n",
        "    print(len(points))\n",
        "\n",
        "    for pair in POSE_PAIRS:\n",
        "        partFrom = pair[0]\n",
        "        partTo = pair[1]\n",
        "        assert(partFrom in BODY_PARTS)\n",
        "        assert(partTo in BODY_PARTS)\n",
        "\n",
        "        idFrom = BODY_PARTS[partFrom]\n",
        "        idTo = BODY_PARTS[partTo]\n",
        "\n",
        "        if points[idFrom] and points[idTo]:\n",
        "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
        "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "    freq = cv.getTickFrequency() / 1000\n",
        "    cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "    print(points)\n",
        "    \n",
        "    cv2_imshow(frame)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getpoints(\"/content/drive/MyDrive/capstone/single pose/madhurima di not crossing the road.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MSIjPcXuMzqm",
        "outputId": "9f57b600-f300-4103-84f0-5760b8066645"
      },
      "id": "MSIjPcXuMzqm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getpoints(\"/content/drive/MyDrive/capstone/single pose/o1 crossing the road.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hkg2ivfZM34A",
        "outputId": "694a6a04-2d27-470d-ca20-ac81fdeba003"
      },
      "id": "Hkg2ivfZM34A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pg7-agBKa5kY"
      },
      "id": "pg7-agBKa5kY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}